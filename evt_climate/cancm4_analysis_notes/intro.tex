\begin{Large}
% \noindent \textbf{Extreme value comparison of CanCM4 simulations and observations}
% \noindent \textbf{Comparison of extreme values of different climate model simulations and observations}
\noindent \textbf{Extreme value comparison of different climate model simulations and observations}
\end{Large}
\bigskip

%\begin{large}
\noindent Mickey Warner, Bruno Sans{\'o}
%end{large}


\bigskip
\bigskip
\begin{quote}
\textbf{Abstract.} Our goal is to explore similarities and differences in extreme behavior between climate simulations and an observation product. We fit a Bayesian hierarchical threshold exceedance model to replicates of CanCM4 climate simulations. Three simulation classes are analyzed and compared: decadal, historical, and pre-industrial control. We extend the comparison to an observation product. To assess the extremes of the series considered we fit a generalized Pareto model to the exceedances over a threshold. This model is applied for data over California and the contiguous United States. Marginal comparisons are made visually with posterior parameter intervals and numerically using the Bhattacharyya distance between probability densities. We find that in some domains, the simulations are in agreement among themselves and with the observations, but in others they are quite different. We also perform a bivariate extreme value analysis using simple Pareto processes.
\end{quote}

\section{Introduction}
\label{intro}

The main focus of this paper is to compare the extreme values of an observation product with those of CanCM4 climate simulations. Specifically, a key question we address is, ``With respect to the extremes, could the observations have come from the climate model?'' The answer to this question would inform us whether the climate model is a reasonable representation of observed extremes.

The Fourth Generation Coupled Global Climate Model (CanCM4) from the Canadian Centre for Climate Modeling and Analysis (CCCma) is made up of an atmospheric component, CanAM4 \citep{von2013canadian}, and an ocean component, CanOM4. The two components are coupled daily to produce climate predictions of a variety of variables on a roughly $2.5^\circ$ degree grid over the globe (see \cite{merryfield2013canadian}). Two variables will be analyzed: precipitation (labled \texttt{pr}, in meters) and maximum temperature (labeled \texttt{tasmax}, in Kelvin). We further restrict our attention to analyzing two seasons---summer and winter---and two regions---California and the U.S.

Three experimental classes that are of particular interest are decadal, historical, and pre-industrial control runs. The decadal simulations provide climate estimates for ten years into the future, after conditioning on the state of the ocean at the time. We consider two decades in this analysis: 1962--1971 and 1990--1999, which are conditioned on ocean states in 1961 and 1989, respectively. Historical simulations are obtained for the years 1961--2005 and are noted for including events that affect the climate such as volcanoes. The pre-industrial control, or simply control, simulations begin at climate conditions comparable to those preceding the industrial revolution and are run over a thousand years. The purpose of the control runs is to provide some measure of internal variability of the climate system. Decadal and historical simulations are run at $R=10$ different input settings. To obtain $R=10$ ``replicates'' for the control simulations, we randomly select ten non-overlapping 10-year periods.

An observation product is obtained from \cite{maurer2002long}. The observations are based on daily measurements from weather stations throughout the United States and are interpolated onto a fine grid (about $1/8^\circ$ degree spacing). To make the observations comparable to the climate simulations, we take weighted sums or averages of the climate simulations and just sums or averages of the observations. See section \ref{process} for details, along with other changes made to the data in preparation for analysis.

The classic approach to analyzing extreme values is to model block maxima (e.g. annual maxima). It can be shown that under certain conditions the block maxima of independent random variables has a distribution which belongs to the generalized extreme value (GEV) family of distributions. Such an approach naturally requires omitting a large portion of the data. This can be remedied by using a threshold exceedance model which involves selecting some large threshold and fitting the exceedances to the generalized Pareto distribution (GPD). We take the threshold exceedance approach in this paper (section \ref{thresh}). See \cite{coles2001introduction} for an excellent introduction to these and other approaches in extreme value analysis.

% Being a threshold exceedance analysis, we must concern ourselves with exceedances occuring together within a short time. This is handled by studying the extremal index $\theta$, a measure of dependence among the extremes. With an estimate for $\theta$, we can ``decluster'' the exceedances to obtain independent clusters. The method for estimating $\theta$ and declustering has been generalized to the hierarchical setting, see section \ref{index}.

% Having replicates of a time-series suggests the use of a hierarchical model, described in detail in section \ref{hier}. Under such a framework we can model each series separately, while assuming these series come from a larger population. In the analysis, we will place focus on the mean of this larger population, being akin to the ensemble average in a climate study.

We attempt to answer the question posed at the beginning of this introduction by comparing posterior intervals for statistical model parameters and other quantities such as return level (section \ref{return}) and Bhattacharyya distance (section \ref{bhatta}).


