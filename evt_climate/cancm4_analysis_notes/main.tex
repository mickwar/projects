\documentclass[12pt]{article}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{dsfont}
\usepackage[margin=1in]{geometry}
\usepackage[font=scriptsize]{caption}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{bm}
\newcommand{\m}[1]{\mathbf{\bm{#1}}}
\newcommand{\R}{I\hspace{-4.4pt}R}
\newcommand{\bc}[1]{\textcolor{blue}{\mathbf{#1}}}
\newcommand{\ind}{\mathds{1}}
\newcommand{\m}[1]{\mathbf{\bm{#1}}}
\newcommand{\R}{I\hspace{-4.4pt}R}

% \setlength\parindent{0pt}


\begin{document}

\begin{Large}
\noindent \textbf{Extreme value comparison of CanCM4 simulations and observations}
\end{Large}
\bigskip

%\begin{large}
\noindent \textbf{Mickey Warner}
%end{large}


\section{Abstract}
\label{abstract}
We fit a Bayesian hierarchical model to threshold exceedances from CanCM4 climate simulations. Three simulation classes are analyzed: decadal, historical, and pre-industrial control. These are compared against on observation product. We find that in some domains, the simulations are in agreement with the observations, but in others can be quite different.

\section{Introduction}
\label{intro}

The Fourth Generation Coupled Global Climate Model (CanCM4) produces a wide array of atmospheric conditions across the globe. Three experimental classes that are of particular interest are decadal, historical, and pre-industrial control runs.

The decadal simulations provide climate estimates for ten years into the future, after conditioning on weather conditions at the time. We consider two decades in this analysis: 1962--1971 and 1990--1999, which are conditioned on climate states in 1961 and 1989, respectively. Historical simulations are obtained for the years 1961--2005 and are noted for including events that affect the climate such as volcanoes. The pre-industrial control, or simply just control, simulations begin at climate conditions comparable to those preceding the industrial revolution and are run over a thousand years into the future.

Decadal and historical simulations are run at $R=10$ different input settings. To obtain $R=10$ ``replicates'' for the control simulations, we randomly select ten non-overlapping 10-year periods.






Extreme value theory provides the framework for analyzing the stochastic behavior of a process at very large (small) values. This entails calculating the probability distribution of the maximum (minimum) of a sequence of random variabes. 

Equivalently, extreme value analyses study the tails of probability distributions associated with some data generating mechanism. 

In extreme value analyses, a primary interest is to understand 

The standard approach is to appeal to asymtoptic arguments.

We can calculate useful quantities such as return levels.

This allows us to extrapolate beyond the span of historical data.


We compare three types of climate model simulations 

The Fourth Generation Atmospheric General Circulation Model (CanCM4) from Canada 

Decadal, historical, and control runs are used to obtain precipitation and temperature over California and the U.S. We have observational data from Ed Maurer. We will consider two 10-year periods: 1962--1971 and 1990--1999. We will also split these into winter months (December, January, Februrary) and summer months (June, July, August). Precipitation in summer is not analyzed.
\bigskip

Purpose of the univariate analysis?
\bigskip

Details on the differences between decadal, historical, and control runs.
\bigskip

Precipitation based on the observations is summed. Precipitation from the climate model is computed with a weighted sum, based on the number of locations in the observation product.
\bigskip

Description of data processing
\bigskip

Picture of the locations CanCM4/Obs produces
\bigskip

Time-series plot of the variables
\bigskip

\section{Data pre-processing}

\subsection{Aggregation}

\begin{figure}
\begin{center}
\includegraphics[scale=0.26]{figs/cal_mod_box1.pdf}
\includegraphics[scale=0.26]{figs/cal_mod_box2.pdf}
\includegraphics[scale=0.26]{figs/cal_mod_box3.pdf}
\end{center}
\caption{Left: CanCM4 simulation locations. Center: Observation locations. Right: method for computing weighted sum or average for CanCM4 to make values comparable with observations. The data shown are from a single day in January.}
\end{figure}

We will look at daily precipitation and maximum temperature, both over California during the 1990s. The quantities used in the analysis are total precipitation (a weighted sum) and average maximum temperature (weighted). (Expand). This leads to a $R$ univariate time series for each class of simulations. To each time-series is fit a dynamic linear model (DLM) having the first two harmonics. Anomalies are computed by taking the difference of the time-series and the smoothed predictions based on the DLM. For winter we look at only December, January, and February. For summer we have June, July, and August. Finally, we treat the time-series as though there is no gap between the seasons of interest. For example, 28 February is followed immediately by 1 December in the winter analysis. This completes our pre-processing. (After the processing, the sequences are assumed stationary).

\subsection{De-trending}
\label{anomaly}

Each time-series is ``de-trended'' prior to declustering and parameter estimation. For each time-series, we fit a dynamic linear model (DLM) with annual and semi-annual periods. From the DLMs we obtain a smoothed version of the time-series, and then take the difference between the original series with the smoothed version. The differences are called the anomalies and the subsequent analyses are performed on them.

Each analysis is confined to a specific season, either winter or summer. Winter months are defined as December, January, and February, and summer months are June, July, and August. After de-trending based on the whole time-series, we remove all observations that do not belong to the season of interest. The remaining observations are concatenated so that, for example in winter, 28 February is followed immediately by 1 December.

Include picture of smoothed DLM
 
\section{Threshold exceedance model}
\label{thresh}

Under some mild assumptions, for random variable $X$ and for large enough $u$, the distribution of $X-u$ (the exceedance), conditional on $X>u$ is approximately
\begin{align}
P(X-u\leq y|X>u) \approx H(y) = 1 - \left(1+\frac{\xi y}{\sigma}\right)^{-1/\xi} \label{gpapprox}
\end{align}
defined on $\{y:y>0~\mathrm{and}~(1+\xi y/\sigma) >0\}$. $H(y)$ is the distribution function for a generalized Pareto random variable with shape paremeter $\xi\in\R$ and scale $\sigma>0$.

Let $X_1,\ldots,X_n$ be a sequence of i.i.d. random variables and $u$ be a high threshold. Define $Y_i=X_i-u$ for $X_i>u$ be the $k$ exceedances. The likelihood of $(\xi,\sigma)$ is derived from (\ref{gpapprox}) as
\begin{align}
L(y_1,\ldots,y_k;\sigma,\xi)=\sigma^{-k}\sum_{i=1}^k\left(1+\frac{\xi y_i}{\sigma}\right)_+^{-1/\xi-1} \label{gplike}
\end{align}
where $z_+=\max(z,0)$. This provides the basis for an extreme value analysis.

In many cases, the assumption of independence in observations may be too strong. When we have dependent random variables, which is likely the case in a time series, we employ a declustering scheme to obtain independent clusters, discussed in section \ref{index}
\bigskip

% \begin{align*}
% P(X-u\leq y|X > u) &= P(X\leq y+u|X > u) \\
%  &= 1 - P(X> y+u|X > u) \\
%  &= 1 - \frac{P(X>y+u, X>u)}{P(X>u)}  \\
%  &= 1 - \frac{P(X>y+u)}{P(X>u)}  \\
%  &= 1 - \frac{1-P(X-u \leq y)}{P(X>u)}  \\
% \Rightarrow P(Y\leq y) = P(X-u\leq y) &= 1-P(X>u)\left(1 - P(X-u\leq y|X>u)\right) \\
%  &= 1-\zeta\left(1+\frac{\xi y}{\sigma}\right)^{-1/xi} \\
% \end{align*}
% where $\zeta=P(X>u)$.
% \bigskip

\subsection{Hierarchical model}
\label{hier}

Suppose we have $R$ replicates or computer simulations, each with $n_i$ observations, for $i=1,\ldots,R$. Let $X_{ij}$ denote the $j$th observation in replicate $i$. We assume
\[ X_{ij} \sim F_i,~~~~~i=1,\ldots,R,~~~~~j=1,\ldots,n_i \]
and all $X_{ij}$ are mutually conditionally independent. From (\ref{gplike}), we deriv

For a fixed $u$ and each $i$, define the following sets:
\[ A_i = \{j:x_{ij}\leq u\},~~~ A_i^c = \{j: x_{ij}>u\} \]
where $|A_i|=n_i-k_i$ and $|A_i^c|=k_i$ with $k_i$ being the number of exceedances in replicate $i$. We define our exceedances as
\[ y_{ij} = (x_{ij}-u)\cdot \ind_{(j \in A_i^c)} \]
so that all observations not exceeding $u$ are marked as $0$. Let $\m{y}_i=(y_{i,1},\ldots,y_{i,n_i})^\top$ and $\m{y}=(\m{y}_1^\top,\ldots,\m{y}_R^\top)^\top$.
\bigskip

The likelihood is given by
\begin{align}
L(\m{y}; \m{\sigma}, \m{\xi}, \m{\zeta}) &= \prod_{i=1}^R f_{Y_i}(\m{y}_i|\sigma_i,\xi_i,\zeta_i) \nonumber \\
&= \prod_{i=1}^R\left[\prod_{j\in A_i} F_{X_i}(u) \times \prod_{j\in A_i^c} f_{X_i}(y_{ij}+u)\right] \nonumber \\
&\approx \prod_{i=1}^R\left[\prod_{j\in A_i} F_{X_i}(u) \times \prod_{j\in A_i^c} [1-F_{X_i}(u)]h(y_{ij}|\sigma_i,\xi_i)\right]~~~~~\mathrm{(approximation~(\ref{gpapprox}))} \nonumber \\
&= \prod_{i=1}^R\left[\prod_{j\in A_i} (1-\zeta_i)\times \prod_{j\in A_i^c} \frac{\zeta_i}{\sigma_i}\left(1+\xi_i\frac{y_{ij}}{\sigma_i}\right)_+^{-1/\xi_i-1}\right]~~~~~\mathrm{(\zeta_i=1-F_{X_i}(u))} \nonumber \\
&= \prod_{i=1}^R\left[(1-\zeta_i)^{n_i-k_i}\zeta_i^{k_i}\prod_{j\in A_i^c}\frac{1}{\sigma_i}\left(1+\xi_i\frac{y_{ij}}{\sigma_i}\right)_+^{-1/\xi_i-1}\right] \label{biglike}
\end{align}

Note that the parameters describing the tail of $F_i$ (i.e. $\xi_i,\sigma_i$) depend only on those observations which exceed $u$. The parameter $\zeta_i=P(X_i>u)$, which is necessary for calculating return levels (section \ref{return}), is based only on the number of exceedances.

We complete the hierarchical model formulation by specifying the following priors:
\begin{align}
\xi_i|\xi, \tau^2  &\sim Normal(\xi, \tau^2) \nonumber \\
\sigma_i|\alpha, \beta &\sim Gamma(\alpha, \beta) \nonumber \\
\zeta_i|\zeta, \eta &\sim Beta(\zeta\eta, (1-\zeta)\eta) \nonumber \\
 \label{priors} \\
\xi &\sim Normal(m, s^2)&  &\tau^2 \sim Gamma(a_\tau, b_\tau) \nonumber \\
\alpha &\sim Gamma(a_\alpha, b_\alpha)&  &\beta \sim Gamma(a_\beta, b_\beta) \nonumber \\
\zeta &\sim Beta(a_\zeta, b_\zeta)&  &\eta \sim Gamma(a_\eta, b_\eta) \nonumber
\end{align}

\section{Extremal Index}
\label{index}

The previously described model relies on an assumption of independence which is unrealistic for a time-series. When there is dependence between the random variables, the extremes are related according to the so-called extremal index, denoted by $\theta$.

\subsection{Estimation}

Ferro and Suveges propose ways for estimating $\theta$. It was our experience that the likelihood provided by Ferro worked better in estimating $\theta$ in a hierarchical setting than the likelihood proposed by Suveges. 

Copy details from the other notes.

\subsection{Declustering}



\section{Return levels}
\label{return}

The $m$-observation return level is
\begin{align}
x_m = u +\frac{\sigma}{\xi}\left[\left(m\zeta\theta\right)^\xi-1\right] \label{rl}
\end{align}

The posterior mean for $\theta$ is used, not samples, when obtaining the return levels.


\section{Results}
\label{results}

\begin{figure}
\begin{center}
\includegraphics[scale=0.72]{figs/shape.pdf}
\end{center}
\caption{Posterior shape parameter, $\xi$, under each domain and each of the four data types. The points are the means and the lines mark the 95\% h.p.d. intervals. The value above each point is the threshold used in the analysis. Note: The $x$-axes are the same for every plot. The $y$-axes (for all subsequent figures) denote only the data type and thus hold no quantitative meaning.}
\label{ksi}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[scale=0.72]{figs/log_sigma.pdf}
\end{center}
\caption{Natural logarithm of the posterior scale. For the CanCM4 simulations, the parameter shown is $\log (\alpha/\beta)$ (the mean scale) because $\sigma_i$ follows a Gamma distribution with mean $\alpha/\beta$. No change of variables is necessary for the observations. Note: The $x$-axes are the same for every plot.}
\label{sigma}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[scale=0.72]{figs/rl20.pdf}
\end{center}
\caption{20-year return levels. Note: The left two columns have the same $x$-axes, which are different than those in the right two columns, which have the same.}
\label{20rl}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[scale=0.72]{figs/rl50.pdf}
\end{center}
\caption{50-year return levels. The $x$-axes are the same as those in Figure \ref{20rl}.}
\label{50rl}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[scale=0.72]{figs/theta.pdf}
\end{center}
\caption{The mean extremal index. Like the parameters shown in Figures \ref{ksi} and \ref{sigma}, the hierarchical mean is shown for the CanCM4 simulations.}
\end{figure}

\section{Discussion}
\label{discussion}





\end{document}
