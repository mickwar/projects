\section{Bivariate analysis}
\label{bivariate}

% \cite{weller2012investigation}  % for bivariate analysis

The univariate analysis described in section \ref{margin} may reveal comparable extremal behavior among some of the simulations and observations, but it is insufficient to describe any tail dependence. For this, we work under the framework of multivariate extremes.

Univariate extreme value analysis can be generalized to a multivariate setting, wherein the limiting model for joint maxima is obtained. The model is comparable to the GEV distribution in the univariate case and further allows the modeling of tail dependence. Chapter 8 of \cite{coles2001introduction} provides a mathematical introduction to multivariate extremes, specifically in the bivariate case. Some possible families of distributions for modeling bivariate extremes are offered in \cite{coles1991modelling}.

Why is it more difficult?

for some of the work done in multivariate extremes
\cite{goix2015sparsity} talk about some really complicated crap for modeling multivariate extremes

\cite{de1977limit} more complicated crap, limit theory for multiextremes



% Dependence in the tails cannot be measured using a typical correlation which measures dependence in the center of the distribution. This gives rise to a statistic which measures asymptotic tail dependence discussed in section \ref{asy_tail}.

% Extremes are rare by definition, so increasing the number of dimensions exacerbates the issue of working with too few data points. For a threshold exceedance model, it is unclear how to appropriately select a multivariate threshold. 

We perform several bivariate analyses using Pareto processes to model the joint tail behavior.

\subsection{Simple Pareto processes}
\label{simp_par}

The primary result we use is Theorem 3.2 from \cite{ferreira2014generalized}. Let $C(S)$ be the space of continuous real functions on $S$, equipped with the supremum norm, where $S$ is a compact subset of $\R^d$. Let $X$ be from $C(S)$. Then the conditions of their Theorem 3.1 imply
\[ \lim_{t\rightarrow\infty} P\left(T_t X \in A \middle| \sup_{s\in S} T_t X(s) > 1\right) = P(W \in A) \]
with $A \in \mathcal{B}(C_1^+(S))$, $P(\partial A)=0$, $W$ some simple Pareto process (see Appendix \ref{def_spp}), and
\[ T_t X = \left(1 + \xi \frac{X - u_t}{\sigma_t}\right)_+^{1/\xi}. \]
This theorem provides us with the means of transforming our data to a Pareto process, which we will in turn use to describe asymptotic tail dependence.

We assume $t$ is large enough that the theorem applies (implying $u=u_t$ and $\sigma=\sigma_t$). Being interested in the bivariate case we can think of $S$ as a set containing two elements only, $s_1$ and $s_2$, which correspond to the two sets of climate data being compared. For notational convenience, instead of specifying an $s\in S$ for each data source and factor combination, we use $s_1$ and $s_2$ for all comparisons.

We further assume that the parameters $\xi$ and $\sigma$ are indexed by $s\in S$, so that our transformation is
\[ T_t X(s) = \left(1 + \xi(s) \frac{X(s) - u_t(s)}{\sigma_t(s)}\right)_+^{1/\xi(s)}. \]
The first stage of our analysis involves estimating $\xi(s)$ and $\sigma(s)$ marginally, which is accomplished by selecting a high threshold $u(s)$ and fitting the generalized Pareto distribution to the excesses $X(s)-u(s)$. The posterior means $\hat{\xi}(s)$ and $\hat{\sigma}(s)$ are then used for the transformation from $X(s)$ to $W(s)$.

Every observation of $X(s)$, say $X_1(s),\ldots,X_{n(s)}(s)$ is transformed with
\begin{align}
W_i(s) = T_t X_i(s) = \left(1 + \hat{\xi}(s) \frac{X_i(s) - u_t(s)}{\hat{\sigma}(s)}\right)_+^{1/\hat{\xi}(s)},~~~~~i=1,\ldots,n(s) \label{transform}
\end{align}
forming the vector $\m{W}(s)=(W_1(s),\ldots,W_{n(s)}(s))^\top$. After performing this transformation, two components are combined to form a joint vector $(W(s_1), W(s_2))$ having realizations $\m{W}_{12}=(\m{W}(s_1), \m{W}(s_2))$, an $n(s)\times 2$ matrix. Note that when we perform the bivariate analysis, we guarantee that $n(s_1)=n(s_2)=n(s)$.

By Theorem 3.2, $\m{W}_{12}$ has rows that are realizations of a simple Pareto process. By the constructive definition of a simple Pareto process (Appendix \ref{def_spp}), we can write $\m{W}_{12}$ as
\[ \m{W}_{12} = \left(\begin{array}{rr} Y_1V_1(s_1) & Y_1V_1(s_2) \\ Y_2V_2(s_1) & Y_2V_2(s_2) \\ \multicolumn{2}{c}{\vdots} \\ Y_nV_n(s_1) & Y_nV_n(s_2) \end{array}\right) \]
where $Y_i$ is a standard Pareto random variable, $V_i(s_j)\geq 0$ ($j=1,2$), and $V_i(s_1) \vee V_i(s_2) = 1$, for $i=1,\ldots,n=n(s)$. This is easily obtained by
\[ Y_i = W_i(s_1) \vee W_i(s_2),~~~\mathrm{and}~~~ V_i(s_j) = W_i(s_j) / Y_i ~~~ (j=1,2),~~~~~\mathrm{for~}i=1,\ldots,n, \]
where $a \vee b=\max(a,b)$. The points $(V_i(s_1), V_i(s_2))$ fall along the curve of the non-negative unit sphere with supremum norm $\{(v_1, v_2):||(v_1,v_2)||_\infty=1, v_1\geq0,v_2\geq0\}$ which is thus one dimensional. An alternative representation is to specify $(V_i(s_1), V_i(s_2))$ in terms of a scaled angle
\[ \phi_i = \frac{2}{\pi}\arctan\left(\frac{V_i(s_2)}{V_i(s_1)}\right)\in[0,1]. \]
We scale $\phi_i$ to be in $[0,1]$ so we can model the density of the angles using a Bernstein-Dirichlet prior (BDP) \citep{petrone1999bayesian}. Since we will be fitting models to many sets of $\phi_i$'s, we desire a model that is flexible at capturing a large variety of possible distributions. The BDP is fit using the \texttt{R} package \texttt{DPpackage}.

Since Theorem 3.2 holds when $\sup_{s\in S}T_t X(s) > 1$ we need only those $\phi_i$ for which $Y_i>1$. This corresponds to only using the angles that are associated with a threshold exceedance. Also, because the BDP has difficulty when too much mass is on the edges, we make the following adjustment. The $\phi_i\in[0, 0.005]$ are treated as zero and those in $[0.995, 1]$ are treated as one. The remainder are used in the BDP model. We find that $k_{max}=300$, which determines the maximum degree of Bernstein polynomials the model is to allow for, was acceptable when applied to the angles.



\subsection{Asymptotic tail dependence}
\label{asy_tail}

We wish to characterize the strength of tail dependence for climate simulation and observation pairs. This is typically done with the following statistic. Suppose $X$ and $Y$ share a common marginal distribution. Then
\[ \chi = \lim_{z\rightarrow z^*} P(X>z| Y>z), \]
where $z^*$ is the (possibly infinite) right end-point, informs us of the distribution of extremes for one variable $X$ given that another variable $Y$ is very large. When $\chi>0$, $X$ and $Y$ are said to be asymptotically dependent, otherwise they are asymptotically independent.

Under the simple Pareto process from section \ref{simp_par}, the distribution function for $W_i\equiv W(s_i)$ is
\[ F_{W_i}(w) = 1 - \frac{E(V_i)}{w} \]
where $V_i\equiv V(s_i)$ and $w>1$. Using this fact, we can standardize $W_i$ to be uniform and compute $\chi$ in this way
\begin{align}
\chi &= \lim_{u\rightarrow 1} P(F_{W_1}(W_1) > u | F_{W_2}(W_2) > u) \nonumber \\
&= E\left(\frac{V_1}{E(V_1)} \wedge \frac{V_2}{E(V_2)}\right), \label{ppchi}
\end{align}
where $a \wedge b=\min(a,b)$. The major downside to the simple Pareto process is that we do not allow for asymptotic independence unless $P(V_1 \wedge V_2=0)=1$, which would require conditioning on a set of zero probability. \cite{coles1999dependence} note that models which have $\chi>0$, as ours does, would necessarily overestimate the degree of dependence in the tail.

