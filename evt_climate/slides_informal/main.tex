\documentclass[mathserif, 11pt, t]{beamer}
\section*{Results}

\input{beamer_setup.tex}

\newcommand{\bc}[1]{\textcolor{blue}{\mathbf{#1}}}

\begin{document}


\titlepage{Extreme value comparison of climate model simulations and observations}{Mickey Warner}{\ }{27 Feb 2018}

%\titlepage{Comparison of extreme values of different climate model simulations and observations}{Mickey Warner}{\ }{30 Oct 2017}



\begin{frame}{Introduction}

CanCM4 simulation classes (with $R=10$ replicates each):
\begin{enumerate}
\item Decadal
\item Historical
\item Control
\end{enumerate}
\bigskip

Observations over U.S. interpolated from weather stations
\bigskip

Factors:
\begin{enumerate}
\item Variable --- Total Precipitation (\texttt{pr}) or Average Maximum Temperature (\texttt{tasmax})
\item Season --- Winter or Summer
\item Decade --- 1962--1971 or 1990--1999
\item Region --- California or USA
\end{enumerate}

\end{frame}



\begin{frame}{Locations}

\begin{figure}
\begin{center}
\includegraphics[scale=0.18]{figs/cal_mod_box1.pdf}
\includegraphics[scale=0.18]{figs/cal_mod_box2.pdf}
\includegraphics[scale=0.18]{figs/cal_mod_box3.pdf}
\end{center}
\caption{Left: CanCM4 simulation grid cells. Center: Observation locations. Right: method for computing weighted sum or average for CanCM4 to make values comparable with observations.}
\end{figure}

\end{frame}



\begin{frame}{Extremes}

For r.v. X and large threshold $u$, the exceedance $Y=X-u$, for $X>u$, approximately follows the generalized Pareto distribution (GPD), which has density

\[ f_Y(y) = \frac{1}{\sigma}\left(1+\xi\frac{y}{\sigma}\right)_+^{-1/\xi-1} \]

\begin{figure}
\begin{center}
\includegraphics[scale=0.22]{figs/tail.pdf}
\end{center}
\end{figure}

\end{frame}



\begin{frame}{Data processing}

Two objectives before performing the analysis:
\begin{enumerate}
\item Make climate simulations comparable to observations
\item Get near-independent random variables for model fitting
\end{enumerate}
\bigskip

These are accomplished by
\begin{enumerate}
\item Taking weighted sums (\texttt{pr}) or weighted averages (\texttt{tasmax})
\item Computing anomalies based on DLMs, and
\item Declustering
\end{enumerate}

\end{frame}



\begin{frame}{Weighted sum or average}
\begin{figure}
\begin{center}
\includegraphics[scale=0.18]{figs/cal_mod_box1.pdf}
\includegraphics[scale=0.18]{figs/cal_mod_box2.pdf}
\includegraphics[scale=0.18]{figs/cal_mod_box3.pdf}
\end{center}
\caption{Left: CanCM4 simulation grid cells. Center: Observation locations. Right: method for computing weighted sum or average for CanCM4 to make values comparable with observations.}
\end{figure}

\end{frame}



\begin{frame}{DLM-based anomaly}
\begin{figure}
\begin{center}
\includegraphics[scale=0.38]{figs/dlm.pdf}
\end{center}
\end{figure}
\end{frame}



\begin{frame}{Extremal index (declustering)}

The extremal index $\theta$ is the inverse of the limiting mean cluster size
\bigskip

It can be estimated using interexceedance times, $T_i = S_{i+1} - S_i$, with a log-likelihood of
\begin{align*}
l(\theta, p; \m{T}) =&~ m_1\log(1-\theta p^\theta) + (N-1-m_1)\{\log(\theta)+ \log(1-p^\theta)\} \nonumber \\
 &+ \theta\log(p)\sum_{i=1}^{N-1}(T_i-1)
\end{align*}
$p$ is the probability of not exceeding the threshold

\end{frame}



\begin{frame}{Declustering}
\begin{figure}
\begin{center}
\includegraphics[scale=0.38]{figs/threshold.pdf}
\end{center}
\end{figure}
\end{frame}

% \begin{frame}{Hierarchical model for threshold exceedance}
% \noindent For the $j$th observation in replicate $i$, we assume
% \[ X_{ij} \overset{ind}\sim F_i,~~~~~i=1,\ldots,R,~~~~~j=1,\ldots,n_i. \]
% \noindent For fixed $u$ and each $i$, define the following sets:
% \[ A_i = \{j:x_{ij}\leq u\},~~~ A_i^c = \{j: x_{ij}>u\} \]
% where $|A_i|=n_i-k_i$ and $|A_i^c|=k_i$ with $k_i$ being the number of exceedances in replicate $i$.
% \bigskip
% 
% \noindent Finally, we define our exceedances as
% \[ y_{ij} = 0\cdot \ind_{(j \in A_i)} + (x_{ij}-u)\cdot \ind_{(j \in A_i^c)} \]
% \end{frame}
% 
% \begin{frame}{Likelihood}
% \noindent The likelihood is given by
% \begin{eqnarray*}
% L(\m{y}; \m{\sigma}, \m{\xi}, \m{\zeta}) &=& \prod_{i=1}^R f_{Y_i}(\m{y}_i|\sigma_i,\xi_i,\zeta_i) \\
% &=& \prod_{i=1}^R\left[\prod_{A_i} F_{X_i}(u) \times \prod_{A_i^c} f_{X_i}(y_{ij}+u)\right] \\
% &\approx& \prod_{i=1}^R\left[\prod_{A_i} F_{X_i}(u) \times \prod_{A_i^c} [1-F_{X_i}(u)]g(y_{ij}|\sigma_i,\xi_i)\right] \\
% &=& \prod_{i=1}^R\left[\prod_{A_i} (1-\zeta_i)\times \prod_{A_i^c} \frac{\zeta_i}{\sigma_i}\left(1+\xi_i\frac{y_{ij}}{\sigma_i}\right)_+^{-1/\xi_i-1}\right] \\
% \end{eqnarray*}
% 
% \end{frame}


\begin{frame}{Likelihood}

Replicate $i$, observation $j$, exceedances $Y_{ij} = X_{ij} - u$, and keep only those $Y_i > 0$. These have likelihood
\[ L(\m{y}; \m{\sigma}, \m{\xi}, \m{\zeta}) = \prod_{i=1}^R\left[(1-\zeta_i)^{n_i-k_i}\zeta_i^{k_i}\prod_{j=1}^{k_i}\frac{1}{\sigma_i}\left(1+\xi_i\frac{y_{ij}}{\sigma_i}\right)_+^{-1/\xi_i-1}\right] \]

$n_i$ is the number of $X_{ij}$'s

$k_i$ is the number of $Y_{ij}$'s

$\zeta_i$ is the probability of exceeding the threshold
% where $n_i$ is number of $X_{ij}$'s and $k_i$ is number of $Y_{ij}$'s, and $\zeta_i$ is the probability of exceeding the threshold

\end{frame}


\begin{frame}{Priors}
\noindent These priors complete the hierarchical model formulation. Greek letters are random variables while English letters are fixed.
\begin{eqnarray*}
\sigma_i|\alpha, \beta &\sim& Gamma(\alpha, \beta) \\
\xi_i|\xi, \tau^2  &\sim& Normal(\xi, \tau^2) \\
\zeta_i|\mu, \eta &\sim& Beta(\mu\eta, (1-\mu)\eta) \\
%\theta_i|\theta_\mu, \theta_\tau &\sim& Beta(\theta_\mu\theta_\tau, (1-\theta_\mu)\theta_\tau) \\
 \\
\alpha_\sigma \sim Gamma(a_\alpha, b_\alpha)&  &\beta_\sigma \sim Gamma(a_\beta, b_\beta) \\
\xi \sim Normal(m, s^2)&  &\tau^2 \sim Gamma(a_\tau, b_\tau) \\
\mu \sim Beta(a_\mu, b_\mu)&  &\eta \sim Gamma(a_\eta, b_\eta) \\
%\theta_\mu \sim Beta(a_{\theta_\mu}, b_{\theta_\mu})&  &\theta_\tau \sim Gamma(a_{\theta_\tau}, b_{\theta_\tau})
\end{eqnarray*}

\end{frame}



\begin{frame}{Return level}

For a distribution $G$, the return level $x_m$ is the solution to
\[ G(x_m) = 1-\frac{1}{m}. \]
The value $x_m$ is exceeded on average once every $m$ observations.
\bigskip

For the GPD, the return level is given by
\[ x_m = u +\frac{\sigma}{\xi}\left[\left(m\zeta\theta\right)^\xi-1\right] \]



\end{frame}




\begin{frame}{Bhattacharyya distance}

Bhattacharyya coefficient
\[ BC(p,q)=\int_\mathcal{X} \sqrt{p(x)q(x)} dx \]

Bhattacharyya distance
\[ D_B(p,q)=-\log BC(p,q). \]

$D_B$ is computed between parameters in the replicates (and observations) and parameters in the hierarchy.

\end{frame}



\begin{frame}
\begin{center}
\includegraphics[scale=0.34]{figs/shape.pdf}
\end{center}
\end{frame}

\begin{frame}
\begin{center}
\includegraphics[scale=0.34]{figs/log_sigma.pdf}
\end{center}
\end{frame}

\begin{frame}
\begin{center}
\includegraphics[scale=0.34]{figs/zeta.pdf}
\end{center}
\end{frame}

\begin{frame}
\begin{center}
\includegraphics[scale=0.34]{figs/rl20.pdf}
\end{center}
\end{frame}

\begin{frame}
\begin{center}
\includegraphics[scale=0.34]{figs/rl50.pdf}
\end{center}
\end{frame}

\begin{frame}
\begin{center}
\includegraphics[scale=0.34]{figs/gp_tail.pdf}
\end{center}
\end{frame}

\begin{frame}
\begin{center}
\includegraphics[scale=0.34]{figs/theta.pdf}
\end{center}
\end{frame}


\begin{frame}{Bivariate analysis}

The univariate analysis allows us to make comparisons between simulations and observations, but not to model their extremal relationship.
\bigskip

A key concept in multivariate extreme value analysis is asymptotic tail dependence, described by the following quantity
\[ \chi = \lim_{z\rightarrow z^*} P(X > z | Y > z) \]
where $X$ and $Y$ share a common marginal distribution and $z^*$ is the (possibly infinite) right end-point of $X$ and $Y$.
\bigskip

Note: even for normal distributions with correlation $\rho < 1$, $\chi=0$.



\end{frame}

\begin{frame}{Simple Pareto process}

For stochastic process $X$, define
\[ T_t X  = \left(1 + \xi\frac{X - u_t}{\sigma_t}\right)_+^{1/\xi}. \]

Under certain conditions,
\[ \lim_{t\rightarrow\infty} P\left(T_t X \in A \middle| \sup_{s\in S} T_t X(s) > 1\right) = P(W \in A) \]
where $W$ is a simple Pareto process (SPP).
\bigskip

Note: for SPP, we cannot have $\chi=0$.

\end{frame}

\begin{frame}{Simple Pareto process, continued}

Climate simulations and observations are transformed with
\[ W_i(s_j) = T_t X_i(s_j) = \left(1 + \xi(s_j)\frac{X_i(s_j) - u_t(s_j)}{\sigma_t(s_j)}\right)_+^{1/\xi(s_j)}. \]
using posterior means for $\xi$ and $\sigma$, where $s_j$ denotes the data source and $i$ denotes individual observations.
\bigskip

Let $\m{W}(s)=(W_1(s),\ldots, W_{n(s)}(s))^\top$, and form the bivariate vector $\m{W}_{12}=(\m{W}(s_1), \m{W}(s_2))$ for some $s_1,s_2$ pair.
\bigskip

Rows of $\m{W}_{12}$ are considered samples from a simple Pareto process.


\end{frame}

\begin{frame}{Bivariate data}
\begin{figure}
\begin{center}
\includegraphics[scale=0.34]{figs/biv_orig.pdf}
\end{center}
\caption{Untransformed data for CA winter precipitation, observations against the first control replicate. Dashed lines mark the thresholds.}
\end{figure}
\end{frame}

\begin{frame}{Bivariate  data}
\begin{figure}
\begin{center}
\includegraphics[scale=0.34]{figs/biv_trans.pdf}
\end{center}
\caption{Data transformed to have Pareto marginals in the exceedances. Red dots mark the points that are kept after declustering.}
\end{figure}
\end{frame}


\begin{frame}{Asymptotic tail dependence for SPP}

Each row of $\m{W}_{12}$ can be written as
\[ (Y_iV_i(s_1), ~ Y_iV_i(s_2)), \]
where $Y_i$ is a standard Pareto random variable and $V_i(s_j)\geq 0$ with $V_i(s_1) \vee V_i(s_2) = 1$, for all $i$.
\bigskip

It can be shown that 
\[ \chi &= E\left(\frac{V(s_1)}{E(V(s_1))} \wedge \frac{V(s_2)}{E(V(s_2))}\right) \]

\end{frame}

\begin{frame}{Bivariate data}
\begin{figure}
\begin{center}
\includegraphics[scale=0.34]{figs/biv_cone.pdf}
\end{center}
\caption{The red dots mark the points $(V_i(s_1), V_i(s_2)$. These are constrained to lie on the unit supremum cone.}
\end{figure}
\end{frame}

\begin{frame}{Asymptotic tail dependence for SPP, continued}

Given the supremum constraint for $V_i(s_1)$ and $V_i(s_2)$, we can write rows of $\m{W}_{12}$ in terms of $Y_i$ and the angle
\[ \phi_i = \frac{2}{\pi}\arctan\left(\frac{V_i(s_2)}{V_i(s_1)}\right)\in[0,1]. \]

The angles $\phi_1,\ldots,\phi_n$ are modeled with a Bernstein-Dirichlet prior (BDP), a flexible model for density estimation.
\bigskip

Posterior samples for $\phi$ are back-transformed to $(V(s_1), V(s_2))$ and $\chi$ is estimated.

\end{frame}


\begin{frame}{Bivariate data}
\begin{figure}
\begin{center}
\includegraphics[scale=0.34]{figs/biv_phi.pdf}
\end{center}
\caption{$(V_i(s_1), V_i(s_2))$ transformed to $ \phi_i$.}
\end{figure}
\end{frame}


\begin{frame}
\begin{center}
\includegraphics[scale=0.34]{figs/chi4.pdf}
\end{center}
\end{frame}





\end{document}
